{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the architecture from (Attention Is All You Need) https://arxiv.org/abs/1706.03762\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic architecture \n",
    "\n",
    "![image.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12cdf506-6cd8-4afa-93a3-b77b82770309_2755x1570.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.gif](https://i.imgur.com/KgZCdzX.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical way to implement the values of the embedding is by hard coding them by using a sine and cosine function of the vectors and elementsâ€™ positions\n",
    "\n",
    "![image.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58a77f49-ed6d-4614-9c64-505455bd0c83_2043x1300.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, context_size: int, d_model: int):\n",
    "        \"\"\"represent positional encoding as harcoded matrix of size (context_size,d_model)\n",
    "\n",
    "        Args:\n",
    "            context_size (int): max context size\n",
    "            d_model (int): model hidden size\n",
    "        \"\"\"\n",
    "        self.encoding = torch.zeros(\n",
    "            size=(context_size, d_model)\n",
    "        )  # placeholder matrix of the encoding , check above figures (orange matrix)\n",
    "        pos = torch.arange(0, context_size).unsqueeze(\n",
    "            dim=1\n",
    "        )  # positions are ranged from 0 to context size (those are rows indexes in orange matrix in above figures)\n",
    "        i = torch.arange(\n",
    "            0, d_model, 2\n",
    "        )  # i range from 0 to d_model in every pos (row in orange matrix)\n",
    "        arg = pos / (10000 ** (2 * i / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(arg)  # even columns (even i)\n",
    "        self.encoding[:, 1::2] = torch.cos(arg)  # odd i\n",
    "\n",
    "    def forward(self, tokens_sequence: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"encode embedded tokens sequence\n",
    "\n",
    "        Args:\n",
    "            tokens_sequence (torch.Tensor):\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: position encoded embedded tokens\n",
    "        \"\"\"\n",
    "        return self.encoding[\n",
    "            : tokens_sequence.shape[1], :\n",
    "        ]  # just query the self.encoding matrix with tokens sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder block is composed of a multi-head attention layer, a position-wise feed-forward network, and two-layer normalization.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6627a678-0582-4950-a829-a8e9e4e97db9_3289x1326.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder is just the token embedding and the position embedding followed by multiple encoder blocks.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3808c9f-715e-4ab0-be11-34e16b3d8644_3540x1022.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Block\n",
    "\n",
    "The decoder block is composed of a multi-head attention layer, a position-wise feed-forward network, a cross-attention layer, and three layer normalization.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0287aa3-7a69-41c4-a692-c1940e007f29_3301x1582.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cross-attention layer computes the attentions between the decoder's hidden states and the encoder output\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fa4f653-3985-40ac-932d-3eb023be2eb0_2723x1332.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder is just the token embedding and the position embedding followed by multiple decoder blocks and the predicting head.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0808f5de-f713-4a56-8750-ac1cda39b929_2753x1542.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicting head is just a linear layer that projects the last hidden states from the d_model dimension to the size of the vocabulary. To predict, we perform an ArgMax function on the resulting probability vectors\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc452d478-581f-4baf-941f-0ab07a39bdb3_3386x1342.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
