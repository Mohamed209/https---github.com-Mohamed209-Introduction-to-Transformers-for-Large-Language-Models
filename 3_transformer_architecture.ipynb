{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the architecture from (Attention Is All You Need) https://arxiv.org/abs/1706.03762\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic architecture \n",
    "\n",
    "![image.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12cdf506-6cd8-4afa-93a3-b77b82770309_2755x1570.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.gif](https://i.imgur.com/KgZCdzX.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical way to implement the values of the embedding is by hard coding them by using a sine and cosine function of the vectors and elementsâ€™ positions\n",
    "\n",
    "![image.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58a77f49-ed6d-4614-9c64-505455bd0c83_2043x1300.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, context_size: int, d_model: int):\n",
    "        \"\"\"represent positional encoding as harcoded matrix of size (context_size,d_model)\n",
    "\n",
    "        Args:\n",
    "            context_size (int): max context size\n",
    "            d_model (int): model hidden size\n",
    "        \"\"\"\n",
    "        self.encoding = torch.zeros(\n",
    "            size=(context_size, d_model)\n",
    "        )  # placeholder matrix of the encoding , check above figures (orange matrix)\n",
    "        pos = torch.arange(0, context_size).unsqueeze(\n",
    "            dim=1\n",
    "        )  # positions are ranged from 0 to context size (those are rows indexes in orange matrix in above figures)\n",
    "        i = torch.arange(\n",
    "            0, d_model, 2\n",
    "        )  # i range from 0 to d_model in every pos (row in orange matrix)\n",
    "        arg = pos / (10000 ** (2 * i / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(arg)  # even columns (even i)\n",
    "        self.encoding[:, 1::2] = torch.cos(arg)  # odd i\n",
    "\n",
    "    def forward(self, tokens_sequence: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"encode embedded tokens sequence\n",
    "\n",
    "        Args:\n",
    "            tokens_sequence (torch.Tensor):\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: position encoded embedded tokens\n",
    "        \"\"\"\n",
    "        return self.encoding[\n",
    "            : tokens_sequence.shape[1], :\n",
    "        ]  # just query the self.encoding matrix with tokens sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder block is composed of a multi-head attention layer, a position-wise feed-forward network, and two-layer normalization.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6627a678-0582-4950-a829-a8e9e4e97db9_3289x1326.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention layer allows to learn complex relationships between the hidden states, whereas the position-wise feed-forward network allows to learn complex relationships between the different elements within each vector.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf4bdbd2-8e45-4f33-9c86-35eede3571ab_3433x1050.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, n_attention_heads: int, d_ff: int, d_model: int):\n",
    "        \"\"\"init encoder\n",
    "\n",
    "        Args:\n",
    "            n_attention_heads (int): number of attention heads\n",
    "            d_ff (int): dimention feed forward network\n",
    "            d_model (int): encoder hidden size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, n_attention_heads)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            hidden_states (torch.Tensor): hidden state tensor is elementwise addition between token embeddings and positional embeddings\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: encoder projection tensor (encoder output)\n",
    "        \"\"\"\n",
    "        out1 = (\n",
    "            self.self_attn(query=hidden_states, key=hidden_states, value=hidden_states)\n",
    "            + hidden_states  # apply resiudal connection\n",
    "        )  # perform self attention on hidden states (note hidden state tensor is elementwise addition between token embeddings and positional embeddings)\n",
    "        norm1 = self.norm1(out1)  # layer normalization\n",
    "        out2 = self.feed_forward(norm1) + norm1\n",
    "        out3 = self.norm2(out2)\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder is just the token embedding and the position embedding followed by multiple encoder blocks.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3808c9f-715e-4ab0-be11-34e16b3d8644_3540x1022.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        context_size: int,\n",
    "        n_blocks: int,\n",
    "        n_heads: int,\n",
    "        d_model: int,\n",
    "        d_ff: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEncoding(context_size, d_model)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                EncoderBlock(\n",
    "                    d_model=d_model,\n",
    "                    num_heads=n_heads,\n",
    "                    d_ff=d_ff,\n",
    "                )\n",
    "                for _ in range(n_blocks)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens_seq: torch.Tensor) -> torch.Tensor:\n",
    "        embedded_tokens = self.embedding(\n",
    "            tokens_seq\n",
    "        )  # apply embeddings layer to tokens input sequence\n",
    "        pos_embedded_tokens = self.pos_embedding(tokens_seq)\n",
    "        hidden_states = embedded_tokens + pos_embedded_tokens\n",
    "        for block in self.blocks:\n",
    "            hidden_states = block(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Block\n",
    "\n",
    "The decoder block is composed of a multi-head attention layer, a position-wise feed-forward network, a cross-attention layer, and three layer normalization.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0287aa3-7a69-41c4-a692-c1940e007f29_3301x1582.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cross-attention layer computes the attentions between the decoder's hidden states and the encoder output\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fa4f653-3985-40ac-932d-3eb023be2eb0_2723x1332.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder is just the token embedding and the position embedding followed by multiple decoder blocks and the predicting head.\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0808f5de-f713-4a56-8750-ac1cda39b929_2753x1542.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicting head is just a linear layer that projects the last hidden states from the d_model dimension to the size of the vocabulary. To predict, we perform an ArgMax function on the resulting probability vectors\n",
    "\n",
    "![img.png](https://cdn.fs.teachablecdn.com/ADNupMnWyR7kCWRvm76Laz/https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc452d478-581f-4baf-941f-0ab07a39bdb3_3386x1342.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
